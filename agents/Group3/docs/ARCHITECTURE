# Architecture Overview

This document describes the high-level architecture of the agent, explaining how the main system components interact and the design decisions involved. The architecture is designed to maximise search efficiency while maintaining flexibility for the neural network integration and experimentation.

## System Overview
The agent is composed of three main components: a C++ Monte Carlo Tree Search (MCTS) engine, a Python interface layer, and a neural network evaluation module. These components are loosely coupled to allow efficient execution while keeping the system modular and extensible. The C++ engine handles performance-critical tasks, while Python is used for neural network inference and training.

### C++ MCTS Engine
The C++ component is responsible for implementing the core game logic and the MCTS algorithm. It manages the search tree, including node expansion, selection, and backup. PUCT-style scoring is used during selection to balance exploration and exploitation. GRAVE (AMAF-based) statistics are also incorporated to improve early-game decision making when node visit counts are low.

The engine performs efficient terminal state detection using BFS-based win checks for both Red and Blue players. Optimisations such as careful memory layout and reduced redundant computation are used to maximise simulation throughput. By implementing the search in C++, the agent can perform significantly more simulations per move than a Python-only implementation.

### Python Interface Layer
The Python layer acts as a bridge between the C++ search engine and the neural network. Communication between C++ and Python is handled using ctypes, allowing the C++ engine to request neural network evaluations during search.

When the C++ engine reaches a leaf node that requires evaluation, the corresponding board state is passed to Python. Python then invokes the neural network, collects the policy and value outputs, and returns them to the C++ engine for node expansion and backup. This design allows neural network inference to remain flexible while keeping the search loop fast.

### Neural Network
The neural network module provides policy and value estimates used to guide the MCTS search. It is based on an Azalea-style architecture and operates on a NumPy representation of the board state. The policy head produces a probability distribution over legal moves, while the value head estimates the expected outcome of the game from the current position.

The network is trained using self-play data generated by MCTS, starting from a pretrained Azalea baseline. During inference, batching is used to reduce overhead and improve GPU utilisation.

### Reasons for design
Separating the search engine from the neural network allows each component to be optimised independently. C++ ensures high simulation throughput, while Python and PyTorch provide fast development and experimentation for neural network models.
